{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report\n",
    "---\n",
    "This repositori contains the solution for the Navigation challenge of the Deep Reinforcement Learning Nano Degree on Udacity.\n",
    "\n",
    "It consists of the following files:\n",
    "`Navigation.ipynb`\n",
    "`model.py`\n",
    "`dqn_agent.py`\n",
    "`checkpoint.pth`\n",
    "`README.md`\n",
    "`Report.ipynb`\n",
    "#### 1. Navigation.ipynb\n",
    "Contains the main structure of the program for loading the environment and training the dqn algorithm.\n",
    "#### 2. model.py\n",
    "Contains the code for the neural network for the dqn algorithm.\n",
    "The neural network is made up of two fully connected layer activated with ReLU activation function. Each of the laywers has 64 neurons. The input layer size is 37.\n",
    "#### 3. dqn_agent.py\n",
    "Contains the code for training the dqn algorithm with experience replay.\n",
    "#### 4. checkpoint.pth\n",
    "Contains the saved weights of the trained neural network from the solution to the environment.\n",
    "#### 5. README.md\n",
    "Contains information about how to setup the project, including installing the Unity environment.\n",
    "#### 6. Report.ipynb\n",
    "Contains the overall report for the solution for the environment.\n",
    "\n",
    "## Deep Q-Network (DQN)\n",
    "\n",
    "With Deep Q-Learning, a deep neural network is used to approximate the Q-function. Given a network F, finding an optimal policy is a matter of finding the best weights w such that F(s,a,w) â‰ˆ Q(s,a).\n",
    "\n",
    "The neural network architecture used for this project can be found here in the model.py file of the source code.\n",
    "\n",
    "\n",
    "# Solution\n",
    "The uploaded solution solves the environment in 322 episodes with the following hyperparameters:\n",
    "n_episodes=1000, eps_start=1.0, eps_end=0.08, eps_decay=0.990, state_size=37, action_size=4, seed=0 ,BUFFER_SIZE = int(1e5) ,BATCH_SIZE = 64,GAMMA = 0.99,TAU = 1e-3,LR = 5e-4 and UPDATE_EVERY = 4        \n",
    "\n",
    "![Training progress](images/Score.png)\n",
    "\n",
    "# Further Work\n",
    "Implement a solution with a double DQN, a dueling DQN and prioritized experience replay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
